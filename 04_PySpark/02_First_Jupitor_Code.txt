!pip install -q findspark

import findspark
findspark.init()

from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()
spark.stop()

import pyspark
from pyspark import SparkConf
from pyspark import SparkContext
conf = SparkConf()
conf.setMaster('local')
conf.setAppName('spark-basic')

sc = SparkContext(conf=conf)

def mod(x):
  import numpy as np
  return (x,np.mod(x,2))
  
rdd = sc.parallelize(range(1000)).map(mod).take(10)
print(rdd)



#If all these line works well, then we are good to go ahead.